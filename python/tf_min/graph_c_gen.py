"""
    TFMin v1.0 Minimal TensorFlow to C++ exporter
    ------------------------------------------

    Copyright (C) 2019 Pete Blacker, Surrey Space Centre & Airbus Defence and
    Space Ltd.
    Pete.Blacker@Surrey.ac.uk
    https://www.surrey.ac.uk/surrey-space-centre/research-groups/on-board-data-handling

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    in the LICENCE file of this software.  If not, see
    <http://www.gnu.org/licenses/>.

    ---------------------------------------------------------------------

    This module contains core ansi-c code generator object. This uses the
    set of operation kernels to generate the c implementation of each layer
    of the model in the provided graph.
"""
import scipy.io
import numpy as np
import struct as st
import argparse
import sys
import os
import random

from tf_min import graph as tfm_g
from tf_min import types
from tf_min import cpp_code_gen as c_gen

from tf_min.v2_kernels import *
from tf_min.v2_kernels.base_op_kernel import BaseOpKernel
from tf_min.v2_kernels.pooling import PoolingOpKernel


class CodeGenerator:
    """
    TFMin ansi-c code generator object.
    """
    BOILER_PLATE = "/* \n    Code generated by TFMin tensorflow to ansi-c " \
                   "converter.\n    Do not edit.\n*/\n"

    def __init__(self, graph, base_name="model_", prefix="", path=".",
                 clang_format=None, byte_order="@", batch_size=1,
                 fake_weights=None):
        """
        Create a CodeGenerator object for the give model and settings
        :param graph: tf_min.Graph, model to export
        :param base_name: String, prefix for all c itentifiers
        :param prefix: String,
        :param path: String, base path to generate code files in.
        :param clang_format: String, or None, the code style to format to.
        :param byte_order: String, struct compatable byte order string, used
                           when writing weight literals as 32 bit hex.
        :param batch_size: Int, the batch size to generate this model with.
        :param fake_weights: Int or None, if an integer then a fake weights
                             buffer of the given size will be used. Allows
                             testing of models on platforms without enough
                             memory to store a models weights.
        """
        # verify that this graph has been sequenced and intermediate
        # tensors have been pre-allocated.
        self.tensor_arena_size = graph.get_peak_memory()
        if self.tensor_arena_size is not None and graph.sequenced():
            # save model and export params
            self.graph = graph
            self.base_name = base_name
            self.prefix = prefix
            self.path = path
            self.clang_format = clang_format
            self.byte_order = byte_order
            self.batch_size = batch_size
            self.fake_weights = fake_weights
            self.export_ready = True
        else:
            # model is not ready for export,
            print("Error: graph given to CodeGeneration object is not ready"
                  "for export.")
            self.graph = None
            self.base_name = None
            self.prefix = None
            self.path = None
            self.clang_format = None
            self.byte_order = None
            self.batch_size = 1
            self.export_ready = False

    def __call__(self, silent=False, debug=False):
        """
        Method which actually generates the c source files of the model and
        its weights.
        :return: True if export successful, False operation
        """
        if not self.export_ready:
            print("Error: Cannot generate code for a graph which isn't ready")
            return

        # ensure the output path exists
        if not os.path.exists(self.path):
          os.mkdir(self.path)

        # Generate the four source files containing this model
        if not silent:
            print("Generating weight header.")
        wh_okay = self.gen_weights_header()
        if not silent:
            if wh_okay:
                print("Complete.")
            else:
                print("Failed.")

        if not silent:
            print("Generating weight source.")
        ws_okay = self.gen_weights_source()
        if not silent:
            if ws_okay:
                print("Complete.")
            else:
                print("Failed.")

        if not silent:
            print("Generating model header.")
        mh_okay = self.gen_model_header()
        if not silent:
            if mh_okay:
                print("Complete.")
            else:
                print("Failed.")

        if not silent:
            print("Generating model source.")
        ms_okay = self.gen_model_source(debug=debug)
        if not silent:
            if ms_okay:
                print("Complete.")
            else:
                print("Failed.")

        if self.clang_format is not None:
          filenames = [os.path.join(self.path, self.base_name + 'model.c'),
                       os.path.join(self.path, self.base_name + 'model.h'),
                       os.path.join(self.path, self.base_name + 'weights.c'),
                       os.path.join(self.path, self.base_name + 'weights.h')]
          clang_command = ("clang-format %s -i -style=%s" % (
            " ".join(filenames),
            self.clang_format
          ))
          clang_stream = os.popen(clang_command)
          clang_result = clang_stream.read().strip()
          if clang_result == "":
            if not silent:
              print("Formatted code to style %s okay." % self.clang_format)
          else:
            print("Failed to format code with error :\n%s" % clang_result)

        if wh_okay and ws_okay and mh_okay and ms_okay:
            if not silent:
                print("All source files generated okay.")
            return True
        else:
            return False

    def gen_weights_header(self):
        """
        Method to generate the header file for the model weights, also
        includes a macro defining the tensor areana size
        :Returns: True if successful, False otherwise
        """
        file_name = self.base_name + "weights.h"
        try:
            file = open(os.path.join(self.path, file_name), "w")
            file.write(CodeGenerator.BOILER_PLATE)
            file.write(self.gen_opening_include_guard(file_name))
            file.write("#include <inttypes.h>\n\n")

            # Add tensor arena size macro
            file.write("#define %sTENSOR_ARENA_SIZE %d /* size of the tensor "
                       "area in bytes */\n\n" % (self.prefix.upper(),
                                                 self.tensor_arena_size))

            if self.fake_weights is None:
                # Add tesnor weight prototypes
                for weight in self.graph.get_constants():
                    file.write(self.gen_weight_proto(weight))
                file.write("\n")
            else:
                file.write("char fake_weights[%d];\n\n" % self.fake_weights)
                for weight in self.graph.get_constants():
                    identifier = self.prefix + c_gen.c_safe_identifier(
                      weight.label)
                    file.write("extern const uint32_t *%s;\n" % identifier)

            file.write(self.gen_closing_include_guard(file_name))
            return True
        except IOError as e:
            print(e)
            return False

    def gen_weights_source(self):
      """Generate"""
      file_name = self.base_name + "weights.c"
      try:
        file = open(os.path.join(self.path, file_name), "w")
        file.write(CodeGenerator.BOILER_PLATE)
        file.write("#include \"%sweights.h\"\n\n" % self.base_name)

        if self.fake_weights is None:
          # Add tesnor weight definitions
          for weight in self.graph.get_constants():
            file.write(self.gen_weight_def(weight))
        else:
          for weight in self.graph.get_constants():
            identifier = self.prefix + c_gen.c_safe_identifier(
              weight.label)
            weights_size = weight.get_buffer_size()
            if weights_size >= self.fake_weights:
              offset = 0
            else:
              weights_d_type_size = types.get_dtype_size(weight.d_type)
              rand_max = ((self.fake_weights - weights_size) /
                          weights_d_type_size)
              offset = random.randint(0, rand_max-1) * weights_d_type_size
            file.write("const uint32_t *%s = (uint32_t*)"
                       "(fake_weights + %d);\n" % (
              identifier, offset
            ))

        return True
      except IOError as e:
        print(e)
        return False

    def gen_model_header(self):
        """Generate"""

        file_name = self.base_name + "model.h"
        try:
            file = open(os.path.join(self.path, file_name), "w")
            file.write(CodeGenerator.BOILER_PLATE)
            file.write(self.gen_opening_include_guard(file_name))
            file.write("#include \"%sweights.h\"\n\n" % self.base_name)

            # define model function prototype
            file.write("void %smodel(%s);\n\n" % (
                self.prefix,
                self.gen_function_paramers()
            ))

            file.write(self.gen_closing_include_guard(file_name))
            return True
        except IOError as e:
            print(e)
            return False

    @staticmethod
    def find_kernel(operation, tags):
        """

        :param operation:
        :param tags:
        :return:
        """
        for kernel in BaseOpKernel.__subclasses__():
            if kernel.matches(operation):
              return kernel

        return None

    def get_preamble_dependencies(self):
      return {}

    def gen_model_fn_preamble(self):
      """
      Method used to generate a specific block of code which is run at the
      start of the model inference function. Used in child classes
      :return: String, c code to add.
      """
      return ""

    def gen_opr_complete_code(self, op_idx):
      """
      Method used to generate a specific block of code after each operation
      has completed, used in child classes.
      :param op_idx: Sequence index of the operation completed
      :return: String, c code to add.
      """
      return ""

    def gen_model_source(self, debug=False):
        """Generate"""
        file_name = self.base_name + "model.c"
        try:
            file = open(os.path.join(self.path, file_name), "w")
            file.write(CodeGenerator.BOILER_PLATE)
            # file.write("#include <float.h>\n")
            file.write("#include \"%smodel.h\"\n" % self.base_name)

            # find the operation kernel for each layer and find all
            # dependencies
            dependencies = self.get_preamble_dependencies()
            if debug:
              dependencies['stdio.h'] = True
            for operation in self.graph.op_sequence:
                kernel = CodeGenerator.find_kernel(operation, tags=[])
                if kernel is not None:
                    kernel_instance = kernel(operation)
                    dependencies.update(kernel_instance.get_dependencies())
            for dependency in dependencies.keys():
                file.write("#include <%s>\n" % dependency)
            file.write("\n")

            # declare model function body
            file.write("void %smodel(%s) {\n" % (
                self.prefix,
                self.gen_function_paramers()
            ))

            # add inference preamble code
            file.write(self.gen_model_fn_preamble())

            # write a code block for each operation
            for idx, operation in enumerate(self.graph.op_sequence):
                file.write("    /* %s op (%s) */\n" % (operation.type,
                                                       operation.label))
                if debug:
                  file.write("    printf(\"Start %s\\n\");\n" % operation.label)
                file.write("    {\n")

                kernel = CodeGenerator.find_kernel(operation, tags=[])
                if kernel is not None:
                    kernel_instance = kernel(operation)
                    file.write(kernel_instance.generate(self.batch_size,
                                                        self.prefix,
                                                        self.fake_weights))
                else:
                    print("Error: Couldn't find kernel to generate "
                          "code for %s operation." % operation.type)

                file.write("    }\n")
                if debug:
                  file.write("    printf(\"End %s\\n\");\n" % operation.label)
                file.write(self.gen_opr_complete_code(idx))

            file.write("}\n")

            return True
        except IOError as e:
            print(e)
            return False

    def gen_file_name(self, suffix):
        """
        Method to generate a full filename from path, base and suffix
        :param suffix: String, the specific source file suffix.
        :return: String, the full filename for this source file.
        """
        return os.path.join(self.path, self.base_name) + suffix

    @staticmethod
    def gen_opening_include_guard(file_name):
        """

        :param file_name:
        :return:
        """
        safe_macro_str = file_name
        safe_macro_str = safe_macro_str.replace('.', '_')
        safe_macro_str = safe_macro_str.replace('-', '_')
        macro = "__" + safe_macro_str.upper() + "__"
        return "#ifndef %s\n#define %s\n" % (macro, macro)

    @staticmethod
    def gen_closing_include_guard(file_name):
        """

        :param file_name:
        :return:
        """
        macro = "__" + file_name.replace(".", "_").upper() + "__"
        return "#endif /* %s */\n" % macro

    def gen_weight_proto(self, tensor):
        """

        :param tensor: TFMin.Tensor object
        :return: String, the prototype of the weights const global definition
        """
        identifier = self.prefix + c_gen.c_safe_identifier(tensor.label)
        return "extern const uint32_t %s[];\n" % identifier

    def gen_function_paramers(self):
        """
        Method to generate a string containing the parameter definitions for
        a model function. All parameters are pointers.
        :return: String
        """
        identifiers = ['tensor_arena']
        d_types = ['void']
        for input in self.graph.get_inputs():
            identifiers.append('const p_' +
                               c_gen.c_safe_identifier(input.label))
            d_types.append(types.get_dtype_c_type(input.d_type))
        for output in self.graph.get_outputs():
            identifiers.append('p_' + c_gen.c_safe_identifier(output.label))
            d_types.append(types.get_dtype_c_type(output.d_type))
        params = []
        for idx, identifier in enumerate(identifiers):
            params.append(d_types[idx] +
                          " *" + identifier)
        return ", ".join(params)

    def gen_weight_def(self, tensor):
        """

        :param tensor:
        :return:
        """
        identifier = self.prefix + c_gen.c_safe_identifier(tensor.label)

        if tensor.value is None:
          print("Tensor [%s] value is None!" % tensor.label)

        if not isinstance(tensor.value, np.ndarray):
            tensor.value = np.array(tensor.value)

        # the value of constant tensors is stored in a np.ndarray the layout
        # will appropriate for direct conversion to a c array layout
        value_flat = tensor.value.flatten(order='C')
        # print("value_flat is [%s]" % str(value_flat))
        # print("flat size is [%s]" % value_flat.size)

        # Constant literals are always written as arrays of unsigned 32 bit
        # integers in hex. This is both a dense format and a precise way of
        # representing floating point values in text.
        struct_type = types.get_dtype_struct_type(tensor.d_type)
        value_buffer = st.pack(self.byte_order + struct_type * value_flat.size,
                               *value_flat)
        # print("Buffer len [%d]" % len(value_buffer))

        # pad the buffer to a multiple of 4 bytes
        pad_len = 4 - len(value_buffer) % 4
        if pad_len == 4:
            pad_len = 0
        value_buffer += bytearray([0] * pad_len)
        # print("Buffer len padd [%d]" % len(value_buffer))

        # write definition as one line (clang format will clean it up)
        int_values = st.unpack(self.byte_order + "I" * int(len(value_buffer)/4),
                               value_buffer)
        hex_values = map(hex, int_values)
        return "const uint32_t %s[] = { %s };\n" % (identifier,
                                                    ", ".join(hex_values))
