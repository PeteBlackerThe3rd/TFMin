"""
    TFMin v1.0 Minimal TensorFlow to C++ exporter
    ------------------------------------------

    Copyright (C) 2019 Pete Blacker, Surrey Space Centre & Airbus Defence and
    Space Ltd.
    Pete.Blacker@Surrey.ac.uk
    https://www.surrey.ac.uk/surrey-space-centre/research-groups/on-board-data-handling

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    in the LICENCE file of this software.  If not, see
    <http://www.gnu.org/licenses/>.

    ---------------------------------------------------------------------

    This module contains core ansi-c code generator object. This uses the
    set of operation kernels to generate the c implementation of each layer
    of the model in the provided graph.
"""
import scipy.io
import numpy as np
import struct as st
import argparse
import sys
import os

from tf_min import graph as tfm_g
from tf_min import types
from tf_min import cpp_code_gen as c_gen


class CodeGenerator:
    """
    TFMin ansi-c code generator object.
    """
    BOILER_PLATE = "/* \n    Code generated by TFMin tensorflow to ansi-c " \
                   "converter.\n    Do not edit.\n*/\n"

    def __init__(self, graph, base_name="model_", prefix="", path=".",
                 clang_format=None, byte_order="@"):
        """

        """

        # verify that this graph has been sequenced and intermediate
        # tensors have been pre-allocated.
        self.tensor_arena_size = graph.get_peak_memory()
        if self.tensor_arena_size is not None and graph.sequenced():
            # save model and export params
            self.graph = graph
            self.base_name = base_name
            self.prefix = prefix
            self.path = path
            self.clang_format = clang_format
            self.byte_order = byte_order
            self.export_ready = True
        else:
            # model is not ready for export,
            print("Error: graph given to CodeGeneration object is not ready"
                  "for export.")
            self.graph = None
            self.base_name = None
            self.prefix = None
            self.path = None
            self.clang_format = None
            self.byte_order = None
            self.export_ready = False

    def __call__(self, silent=False):
        """

        :return: True if expport successful, False operation
        """
        if not self.export_ready:
            print("Error: Cannot generate code for a graph which isn't ready")
            return

        # Generate the four source files containing this model
        if not silent:
            print("Generating weight header.")
        wh_okay = self.gen_weights_header()
        if not silent:
            if wh_okay:
                print("Complete.")
            else:
                print("Failed.")

        if not silent:
            print("Generating weight source.")
        ws_okay = self.gen_weights_source()
        if not silent:
            if ws_okay:
                print("Complete.")
            else:
                print("Failed.")

        if not silent:
            print("Generating model header.")
        mh_okay = self.gen_model_header()
        if not silent:
            if mh_okay:
                print("Complete.")
            else:
                print("Failed.")

        if not silent:
            print("Generating model source.")
        ms_okay = self.gen_model_source()
        if not silent:
            if ms_okay:
                print("Complete.")
            else:
                print("Failed.")

        if wh_okay and ws_okay and mh_okay and ms_okay:
            print("All source files generated okay.")

    def gen_weights_header(self):
        """
        Method to generate the header file for the model weights, also
        includes a macro defining the tensor areana size
        :Returns: True if successful, False otherwise
        """
        file_name = self.base_name + "weights.h"
        try:
            file = open(os.path.join(self.path, file_name), "w")
            file.write(CodeGenerator.BOILER_PLATE)
            file.write(self.gen_opening_include_guard(file_name))
            file.write("#include <inttypes.h>\n")

            # Add tensor arena size macro
            file.write("#define %s_TENSOR_ARENA_SIZE %d /* size of the tensor "
                       "area in bytes */\n" % (self.prefix.upper(),
                                               self.tensor_arena_size))

            # Add tesnor weight prototypes
            for weight in self.graph.get_constants():
                file.write(self.gen_weight_proto(weight))

            file.write(self.gen_closing_include_guard(file_name))
            return True
        except IOError as e:
            print(e)
            return False

    def gen_weights_source(self):
        """Generate"""
        file_name = self.base_name + "weights.c"
        try:
            file = open(os.path.join(self.path, file_name), "w")
            file.write(CodeGenerator.BOILER_PLATE)
            file.write("#include <%sweights.h>\n" % self.base_name)

            # Add tesnor weight definitions
            for weight in self.graph.get_constants():
                file.write(self.gen_weight_def(weight))

            return True
        except IOError as e:
            print(e)
            return False

    def gen_model_header(self):
        """Generate"""
        return True

    def gen_model_source(self):
        """Generate"""
        return True

    def gen_file_name(self, suffix):
        """
        Method to generate a full filename from path, base and suffix
        :param suffix: String, the specific source file suffix.
        :return: String, the full filename for this source file.
        """
        return os.path.join(self.path, self.base_name) + suffix

    @staticmethod
    def gen_opening_include_guard(file_name):
        """

        :param file_name:
        :return:
        """
        macro = "__" + file_name.replace(".", "_").upper() + "__"
        return "#ifndef %s\n#define %s\n" % (macro, macro)

    @staticmethod
    def gen_closing_include_guard(file_name):
        """

        :param file_name:
        :return:
        """
        macro = "__" + file_name.replace(".", "_").upper() + "__"
        return "#endif /* %s */\n" % macro

    def gen_weight_proto(self, tensor):
        """

        :param tensor: TFMin.Tensor object
        :return: String, the prototype of the weights const global definition
        """
        identifier = self.prefix + c_gen.c_safe_identifier(tensor.label)
        return "const uint_32_t %s[];\n" % identifier

    def gen_weight_def(self, tensor):
        """

        :param tensor:
        :return:
        """
        identifier = self.prefix + c_gen.c_safe_identifier(tensor.label)

        print("tensor value is [%s] type [%s]" % (str(tensor.value),
                                                  type(tensor.value)))

        # the value of constant tensors is stored in a np.ndarray the layout
        # will appropriate for direct conversion to a c array layout
        value_flat = tensor.value.flatten(order='C')
        print("value_flat is [%s]" % str(value_flat))
        print("flat size is [%s]" % value_flat.size)

        # Constant literals are always written as arrays of unsigned 32 bit
        # integers in hex. This is both a dense format and a precise way of
        # representing floating point values in text.
        struct_type = "f"  # types.get_dtype_struct_type(tensor.d_type)
        # TODO fix this
        value_buffer = st.pack(self.byte_order + struct_type * value_flat.size,
                               *value_flat)
        print("Buffer len [%d]" % len(value_buffer))

        # pad the buffer to a multiple of 4 bytes
        pad_len = 4 - len(value_buffer) % 4
        if pad_len == 4:
            pad_len = 0
        value_buffer += bytearray([0] * pad_len)
        print("Buffer len padd [%d]" % len(value_buffer))

        # write definition as one line (clang format will clean it up)
        int_values = st.unpack(self.byte_order + "I" * int(len(value_buffer)/4),
                              value_buffer)
        hex_values = map(hex, int_values)
        return "%s[] = { %s };\n" % (identifier,
                                   ",".join(hex_values))
